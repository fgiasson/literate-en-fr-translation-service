{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main\n",
    "\n",
    "> Main application where the translation web service endpoints are defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports\n",
    "\n",
    "We are using `Flask` to define the web service endpoints, and we are using Hugging Face's `transformers` library to load the model and perform the translation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "\n",
    "from flask import Flask, request, jsonify\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Models\n",
    "\n",
    "We are loading the models from the `models` folder. The models are [`MarianMT`](https://huggingface.co/docs/transformers/model_doc/marian) models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def get_model(model_path):\n",
    "    \"\"\"Load a Hugging Face model and tokenizer from the specified directory\"\"\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(model_path)\n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "#| eval: false\n",
    "\n",
    "# Load the models and tokenizers for each supported language\n",
    "en_fr_model, en_fr_tokenizer = get_model('models/en_fr/')\n",
    "fr_en_model, fr_en_tokenizer = get_model('models/fr_en/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Service Endpoints\n",
    "\n",
    "The next step is to use Flask to create the English/French and French/English translation web service endpoints.\n",
    "\n",
    "We first check if the path to the translation web service exists. The two paths currently defined are:\n",
    "\n",
    " - `/translate/en/fr`\n",
    " - `/translate/fr/en`\n",
    "\n",
    "Once the container is running, we can test the web service endpoints using `curl`:\n",
    "\n",
    "```bash\n",
    "curl http://localhost:6000/translate/en/fr/ POST -H \"Content-Type: application/json\" -d '{\"en_text\":\"Hello World!\"}'\n",
    "```\n",
    "\n",
    "The output should be:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"fr_text\": \"Bonjour le monde!\"\n",
    "}\n",
    "```\n",
    "\n",
    "```bash\n",
    "curl http://localhost:6000/translate/fr/en/ POST -H \"Content-Type: application/json\" -d '{\"fr_text\":\"Bonjour le monde!\"}'\n",
    "```\n",
    "\n",
    "The output should be:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"en_text\": \"Hello world!\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "def is_translation_supported(from_lang, to_lang):\n",
    "    \"\"\"Check if the specified translation is supported\"\"\"\n",
    "    supported_translations = ['en_fr', 'fr_en']\n",
    "    return f'{from_lang}_{to_lang}' in supported_translations\n",
    "\n",
    "@app.route('/translate/<from_lang>/<to_lang>/', methods=['POST'])\n",
    "def translate_endpoint(from_lang, to_lang):\n",
    "    \"\"\"Translate text from one language to another. This function is \n",
    "    called when a POST request is sent to `/translate/<from_lang>/<to_lang>/`\"\"\"\n",
    "    if not is_translation_supported(from_lang, to_lang):\n",
    "        return jsonify({'error': 'Translation not supported'}), 400\n",
    "\n",
    "    data = request.get_json()\n",
    "    from_text = data.get(f'{from_lang}_text', '')\n",
    "\n",
    "    if from_text:\n",
    "        model = None\n",
    "        tokenizer = None\n",
    "\n",
    "        match from_lang:\n",
    "            case 'en':        \n",
    "                model = en_fr_model\n",
    "                tokenizer = en_fr_tokenizer\n",
    "            case 'fr':\n",
    "                model = fr_en_model\n",
    "                tokenizer = fr_en_tokenizer\n",
    "\n",
    "        to_text = tokenizer.decode(model.generate(tokenizer.encode(from_text, return_tensors='pt')).squeeze(), skip_special_tokens=True)\n",
    "\n",
    "        return jsonify({f'{to_lang}_text': to_text})\n",
    "    else:\n",
    "        return jsonify({'error': 'Text to translate not provided'}), 400"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrypoint\n",
    "\n",
    "Finally, we define the entry point of the application. This is the file that will be executed when the container is run. It will run the Flask application on port 6000 and enables the debug mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "#| eval: false\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0', port=6000, debug=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
