{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Models\n",
    "\n",
    "> Downloading all the models required by the English/French and French/English translation web services from [Hugging Face](https://huggingface.co). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp download_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports\n",
    "\n",
    "We import the `AutoTokenizer` and `AutoModelForSeq2SeqLM` classes from Hugging Face's transformers library. Those are used to automatically load any type of model and tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Model and Tokenizer Files\n",
    "\n",
    "The next step is to download each `model_name` to the specified `model_path`. For the given `model_name`, the function will download all the appropriate model and tokenizer files to that path. If the specified path is not existing, then it will be created by the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def download_model(model_path: str, model_name: str):\n",
    "    \"\"\"Download a Hugging Face model and tokenizer to the specified directory\"\"\"\n",
    "    # Check if the directory already exists\n",
    "    if not os.path.exists(model_path):\n",
    "        os.makedirs(model_path)\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "    # Save the model and tokenizer to the specified directory\n",
    "    model.save_pretrained(model_path)\n",
    "    tokenizer.save_pretrained(model_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Models\n",
    "\n",
    "The final step is to download the [English/French](https://huggingface.co/Helsinki-NLP/opus-mt-en-fr) translation model and the [French/English](https://huggingface.co/Helsinki-NLP/opus-mt-fr-en) translation model which are two different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "#| eval: false\n",
    "\n",
    "download_model('models/en_fr/', 'Helsinki-NLP/opus-mt-en-fr')\n",
    "download_model('models/fr_en/', 'Helsinki-NLP/opus-mt-fr-en')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
